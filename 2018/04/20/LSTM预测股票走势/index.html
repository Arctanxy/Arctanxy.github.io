<!DOCTYPE html><html lang="zh-cn"><head><meta charset="utf-8"><title>LSTM预测股票走势 |</title><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name="format-detection" content="telephone=no"><meta name="author" content="dalalaa"><meta name="designer" content="minfive"><meta name="keywords" content="null"><meta name="description" content="Machine Learning"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><meta name="format-detection" content="telephone=yes"><meta name="mobile-web-app-capable" content="yes"><meta name="robots" content="all"><link rel="canonical" href="http://yoursite.com/2018/04/20/LSTM预测股票走势/index.html"><link rel="icon" type="image/png" href="undefined" sizes="32x32"><link rel="stylesheet" href="/scss/base/index.css"><link rel="alternate" href="/atom.xml" title="阿呆的读书笔记"><script async src="https://www.googletagmanager.com/gtag/js?id=UA-116821310-1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-116821310-1")</script><link rel="stylesheet" href="/scss/views/page/post.css"></head><body ontouchstart><div id="page-loading" class="page page-loading" style="background-image:url(undefined)"></div><div id="page" class="page js-hidden"><header class="page__small-header page__header--small"><nav class="page__navbar"><div class="page__container navbar-container"><a class="page__logo" href="/" title="阿呆的读书笔记" alt="阿呆的读书笔记"><img src="undefined" alt="阿呆的读书笔记"></a><nav class="page__nav"><ul class="nav__list clearfix"><li class="nav__item"><a href="/" alt="首页" title="首页">首页</a></li><li class="nav__item"><a href="/archives" alt="归档" title="归档">归档</a></li><li class="nav__item"><a href="/about" alt="关于" title="关于">关于</a></li><li class="nav__item"><a href="/search" alt="menu.search" title="menu.search">menu.search</a></li></ul></nav><button class="page__menu-btn" type="button"><i class="iconfont icon-menu"></i></button></div></nav></header><main class="page__container page__main"><div class="page__content"><article class="page__post"><div class="post__cover"><img src="undefined" alt="LSTM预测股票走势"></div><header class="post__info"><h1 class="post__title">LSTM预测股票走势</h1><div class="post__mark"><div class="mark__block"><i class="mark__icon iconfont icon-write"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/">undefined</a></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-time"></i><ul class="mark__list clearfix"><li class="mark__item"><span>2018-04-20</span></li></ul></div><div class="mark__block"><i class="mark__icon iconfont icon-tab"></i><ul class="mark__list clearfix"><li class="mark__item"><a href="/tags/机器学习/">机器学习</a></li><li class="mark__item"><a href="/tags/时间序列/">时间序列</a></li><li class="mark__item"><a href="/tags/TensorFlow/">TensorFlow</a></li><li class="mark__item"><a href="/tags/LSTM/">LSTM</a></li></ul></div></div></header><div class="post__content"><h1 id="使用LSTM预测股票趋势"><a href="#使用LSTM预测股票趋势" class="headerlink" title="使用LSTM预测股票趋势"></a>使用LSTM预测股票趋势</h1><p>参考上一篇利用LSTM预测美元汇率的文章，可以自行编写一个程序用于预测股票涨跌。</p><h2 id="1-工具"><a href="#1-工具" class="headerlink" title="1. 工具"></a>1. 工具</h2><h3 id="数据来源：Tushare"><a href="#数据来源：Tushare" class="headerlink" title="数据来源：Tushare"></a>数据来源：Tushare</h3><p>Tushare是一个开源财经数据包，其数据主要来自新浪财经和腾讯财经，调用起来非常方便。</p><h3 id="模型工具：TensorFlow"><a href="#模型工具：TensorFlow" class="headerlink" title="模型工具：TensorFlow"></a>模型工具：TensorFlow</h3><p>TensorFlow不用过多介绍，本文中采用了自己搭建LSTM神经元的方式构建神经网络，以便与上一篇文章相呼应。</p><h2 id="2-导入数据"><a href="#2-导入数据" class="headerlink" title="2. 导入数据"></a>2. 导入数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    获取历史收盘价格并归一化</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#加载数据</span></span><br><span class="line">    stocks = ts.get_hist_data(code=<span class="string">'600848'</span>,start=<span class="string">'2010-01-01'</span>,end=<span class="string">'2017-12-31'</span>)</span><br><span class="line">    close_data = stocks[<span class="string">'close'</span>].values</span><br><span class="line">    <span class="comment">#归一化</span></span><br><span class="line">    scaler = StandardScaler()</span><br><span class="line">    scaled_data = scaler.fit_transform(close_data.reshape(<span class="number">-1</span>,<span class="number">1</span>))</span><br><span class="line">    <span class="keyword">return</span> scaled_data</span><br></pre></td></tr></table></figure><h2 id="3-处理数据"><a href="#3-处理数据" class="headerlink" title="3. 处理数据"></a>3. 处理数据</h2><p>因为是做预测实验，所以需要将数据按时间分割，下面的代码中将数据分割成了每windowsize个x对应一个y。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">window_data</span><span class="params">(data,window_size)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    切割数据，长度比x:y = 7:1</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    x = []</span><br><span class="line">    y = []</span><br><span class="line">    i = <span class="number">0</span> </span><br><span class="line">    <span class="keyword">while</span> (i + window_size) &lt;= data.shape[<span class="number">0</span>] <span class="number">-1</span>:</span><br><span class="line">        x.append(data[i:i+window_size])</span><br><span class="line">        y.append(data[i+window_size])</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">assert</span> len(x) == len(y)</span><br><span class="line">    <span class="keyword">return</span> x,y</span><br></pre></td></tr></table></figure><p></p><p>分割完了之后要进行数据划分，划分成训练数据和测试数据，以便验证模型效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_test</span><span class="params">(x,y,test_size)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    划分训练与测试数据</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    x_train = np.array(x[:int(len(x)*test_size)])</span><br><span class="line">    y_train = np.array(y[:int(len(x)*test_size)])</span><br><span class="line">    x_test = np.array(x[int(len(x)*test_size):])</span><br><span class="line">    y_test = np.array(y[int(len(x)*test_size):])</span><br><span class="line">    <span class="keyword">return</span> x_train,y_train,x_test,y_test</span><br></pre></td></tr></table></figure><h2 id="4-定义LSTM神经元"><a href="#4-定义LSTM神经元" class="headerlink" title="4. 定义LSTM神经元"></a>4. 定义LSTM神经元</h2><p>下面各个参数的具体功能可以参考<a href="https://arctanxy.github.io/2018/04/15/LSTM%E9%A2%84%E6%B5%8B%E6%B1%87%E7%8E%87%E5%8F%98%E5%8C%96/" target="_blank" rel="noopener">上一篇文章</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">LSTM_cell</span><span class="params">(input,output,state)</span>:</span></span><br><span class="line">    <span class="string">'''</span></span><br><span class="line"><span class="string">    定义LSTM神经元</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">    <span class="comment">#输入门</span></span><br><span class="line">    weights_input_gate = tf.Variable(tf.truncated_normal([<span class="number">1</span>,HIDDEN_LAYER],stddev=<span class="number">0.05</span>))<span class="comment">#tf.truncated_normal用于生成一定维度的正态分布数据</span></span><br><span class="line">    weights_input_hidden = tf.Variable(tf.truncated_normal([HIDDEN_LAYER,HIDDEN_LAYER],stddev=<span class="number">0.05</span>))</span><br><span class="line">    bias_input = tf.Variable(tf.zeros([HIDDEN_LAYER]))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#遗忘门</span></span><br><span class="line">    weights_forget_gate = tf.Variable(tf.truncated_normal([<span class="number">1</span>, HIDDEN_LAYER], stddev=<span class="number">0.05</span>))</span><br><span class="line">    weights_forget_hidden = tf.Variable(tf.truncated_normal([HIDDEN_LAYER, HIDDEN_LAYER], stddev=<span class="number">0.05</span>))</span><br><span class="line">    bias_forget = tf.Variable(tf.zeros([HIDDEN_LAYER]))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#输出门</span></span><br><span class="line">    weights_output_gate = tf.Variable(tf.truncated_normal([<span class="number">1</span>, HIDDEN_LAYER], stddev=<span class="number">0.05</span>))</span><br><span class="line">    weights_output_hidden = tf.Variable(tf.truncated_normal([HIDDEN_LAYER, HIDDEN_LAYER], stddev=<span class="number">0.05</span>))</span><br><span class="line">    bias_output = tf.Variable(tf.zeros([HIDDEN_LAYER]))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#记忆单元</span></span><br><span class="line">    weights_memory_cell = tf.Variable(tf.truncated_normal([<span class="number">1</span>, HIDDEN_LAYER], stddev=<span class="number">0.05</span>))</span><br><span class="line">    weights_memory_cell_hidden = tf.Variable(tf.truncated_normal([HIDDEN_LAYER, HIDDEN_LAYER], stddev=<span class="number">0.05</span>))</span><br><span class="line">    bias_memory_cell = tf.Variable(tf.zeros([HIDDEN_LAYER]))</span><br><span class="line"></span><br><span class="line">    <span class="comment">#定义各个门与状态</span></span><br><span class="line">    input_gate = tf.sigmoid(tf.matmul(input, weights_input_gate) + tf.matmul(output, weights_input_hidden) + bias_input)</span><br><span class="line">    forget_gate = tf.sigmoid(tf.matmul(input, weights_forget_gate) + tf.matmul(output, weights_forget_hidden) + bias_forget)</span><br><span class="line">    output_gate = tf.sigmoid(tf.matmul(input, weights_output_gate) + tf.matmul(output, weights_output_hidden) + bias_output)</span><br><span class="line">    memory_cell = tf.tanh(tf.matmul(input, weights_memory_cell) + tf.matmul(output, weights_memory_cell_hidden) + bias_memory_cell)</span><br><span class="line">    state = state * forget_gate + input_gate * memory_cell</span><br><span class="line">    output = output_gate * tf.tanh(state)</span><br><span class="line">    <span class="keyword">return</span> state, output</span><br></pre></td></tr></table></figure><h2 id="5-训练模型"><a href="#5-训练模型" class="headerlink" title="5. 训练模型"></a>5. 训练模型</h2><h3 id="1-定义参数"><a href="#1-定义参数" class="headerlink" title="(1) 定义参数"></a>(1) 定义参数</h3><p>定义一些必须的模型参数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">7</span><span class="comment">#模型每批次训练所接受的数据量</span></span><br><span class="line">WINDOW_SIZE = <span class="number">7</span><span class="comment">#滑窗法切割</span></span><br><span class="line">HIDDEN_LAYER = <span class="number">256</span><span class="comment">#隐藏层层数</span></span><br><span class="line">CLIP_MARGIN = <span class="number">4</span><span class="comment">#用于控制梯度范围的参数</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.001</span><span class="comment">#步长</span></span><br><span class="line">EPOCHS = <span class="number">100</span><span class="comment">#迭代次数</span></span><br></pre></td></tr></table></figure><h3 id="2-定义变量"><a href="#2-定义变量" class="headerlink" title="(2) 定义变量"></a>(2) 定义变量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    data = get_data()</span><br><span class="line">    x,y = window_data(data,WINDOW_SIZE)</span><br><span class="line">    x_train,y_train,x_test,y_test = train_test(x,y,test_size=<span class="number">0.25</span>)</span><br><span class="line">    inputs = tf.placeholder(tf.float32,[BATCH_SIZE,WINDOW_SIZE,<span class="number">1</span>])</span><br><span class="line">    targets = tf.placeholder(tf.float32,[BATCH_SIZE,<span class="number">1</span>])</span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="comment">#输出参数</span></span><br><span class="line">    weights_output = tf.Variable(tf.truncated_normal([HIDDEN_LAYER,<span class="number">1</span>],stddev=<span class="number">0.05</span>))</span><br><span class="line">    bias_output_layer = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(BATCH_SIZE):</span><br><span class="line">        batch_state = np.zeros([<span class="number">1</span>,HIDDEN_LAYER],dtype=np.float32)</span><br><span class="line">        batch_output = np.zeros([<span class="number">1</span>,HIDDEN_LAYER],dtype=np.float32)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(WINDOW_SIZE):</span><br><span class="line">            batch_state,batch_output = LSTM_cell(tf.reshape(inputs[i][j],(<span class="number">-1</span>,<span class="number">1</span>)),batch_state,batch_output)</span><br><span class="line">        outputs.append(tf.matmul(batch_output,weights_output) + bias_output_layer)</span><br><span class="line">    <span class="comment">#定义模型损失</span></span><br><span class="line">    losses = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(outputs)):</span><br><span class="line">        losses.append(tf.losses.mean_squared_error(tf.reshape(targets[i],(<span class="number">-1</span>,<span class="number">1</span>)),outputs[i]))</span><br><span class="line">    loss = tf.reduce_mean(losses)</span><br><span class="line">    <span class="comment">#定义优化器</span></span><br><span class="line">    gradients = tf.gradients(loss,tf.trainable_variables())<span class="comment">#计算梯度</span></span><br><span class="line">    clipped,_ = tf.clip_by_global_norm(gradients,CLIP_MARGIN)<span class="comment">#让梯度控制在一定范围内，防止梯度消失或者梯度爆炸</span></span><br><span class="line">    optimizer = tf.train.AdamOptimizer(LEARNING_RATE)</span><br><span class="line">    trained_optimizer = optimizer.apply_gradients(zip(gradients,tf.trainable_variables()))</span><br></pre></td></tr></table></figure><h3 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="(3) 训练模型"></a>(3) 训练模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练模型</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(EPOCHS):</span><br><span class="line">    trained_scores = []</span><br><span class="line">    j = <span class="number">0</span></span><br><span class="line">    epoch_loss = []</span><br><span class="line">    <span class="keyword">while</span> (j+BATCH_SIZE) &lt;= len(x_train):</span><br><span class="line">        x_batch = x_train[j:j+BATCH_SIZE]</span><br><span class="line">        y_batch = y_train[j:j+BATCH_SIZE]</span><br><span class="line">        <span class="comment">#c为cost，o为output</span></span><br><span class="line">        o,c,_ = sess.run([outputs,loss,trained_optimizer],feed_dict=&#123;inputs:x_batch,targets:y_batch&#125;)</span><br><span class="line">        epoch_loss.append(c)</span><br><span class="line">        trained_scores.append(o)</span><br><span class="line">        j += BATCH_SIZE</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (i%<span class="number">30</span>) == <span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"Loss:&#123;&#125;"</span>.format(np.mean(epoch_loss)))</span><br></pre></td></tr></table></figure><h2 id="6-检验模型"><a href="#6-检验模型" class="headerlink" title="6. 检验模型"></a>6. 检验模型</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#测试</span></span><br><span class="line">tests = []</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> i+BATCH_SIZE &lt;= len(x_test):</span><br><span class="line">    o = sess.run([outputs],feed_dict=&#123;inputs:x_test[i:i+BATCH_SIZE]&#125;)</span><br><span class="line">    i += BATCH_SIZE</span><br><span class="line">    tests.append(o)</span><br><span class="line"><span class="comment">#因为得到的预测数据是一格一格的滑窗数据，有很多重复数据，需要进行处理</span></span><br><span class="line">tests_new = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(tests)):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(len(tests[i][<span class="number">0</span>])):</span><br><span class="line">        tests_new.append(tests[i][<span class="number">0</span>][j])</span><br><span class="line"><span class="comment">#将结果一维化</span></span><br><span class="line">tests_new = np.squeeze(tests_new)</span><br><span class="line">print(len(data),len(tests_new))</span><br><span class="line">print(tests_new)</span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.plot(range(len(data)),data,color = <span class="string">'r'</span>)</span><br><span class="line">plt.plot(range(len(data)-len(tests_new),len(data)),tests_new,color = <span class="string">'g'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">fig.savefig(<span class="string">"H:/learning_notes/study/ttfunds/prediction.jpg"</span>)</span><br></pre></td></tr></table></figure><p>最终预测结果为：</p><p><img src="https://github.com/Arctanxy/learning_notes/blob/master/study/ttfunds/prediction.jpg?raw=true" alt=""></p><div class="post-announce">感谢您的阅读，本文由 <a href="http://yoursite.com">阿呆的读书笔记</a> 版权所有。如若转载，请注明出处：阿呆的读书笔记（<a href="http://yoursite.com/2018/04/20/LSTM预测股票走势/">http://yoursite.com/2018/04/20/LSTM预测股票走势/</a>）</div><div class="post__prevs"><div class="post__prev"><a href="/2018/04/17/朴素贝叶斯分类器的Python实现/" title="朴素贝叶斯分类器的Python实现"><i class="iconfont icon-prev"></i>朴素贝叶斯分类器的Python实现</a></div><div class="post__prev post__prev--right"><a href="/2018/04/30/OpenCV简单用法（二）/" title="OpenCV简单用法（二）">OpenCV简单用法（二）<i class="iconfont icon-next"></i></a></div></div></div></article></div><aside class="page__sidebar"><form id="page-search-from" class="page__search-from" action="/search/"><label class="search-form__item"><input class="input" type="text" name="search" placeholder="Search..."> <i class="iconfont icon-search"></i></label></form><div class="sidebar__block"><h3 class="block__title">简介</h3><p class="block__text">Machine Learning</p></div><div class="sidebar__block"><h3 class="block__title">文章分类</h3></div><div class="sidebar__block"><h3 class="block__title">最新文章</h3><ul class="block-list latest-post-list"><li class="latest-post-item"><a href="/2018/04/30/OpenCV简单用法（一）/" title="OpenCV简单用法（一）"><div class="item__cover"><img src="/img/OpenCV简单用法/Diablo.jpg" alt="OpenCV简单用法（一）"></div><div class="item__info"><h3 class="item__title">OpenCV简单用法（一）</h3><span class="item__text">2018-04-30</span></div></a></li><li class="latest-post-item"><a href="/2018/04/30/OpenCV简单用法（二）/" title="OpenCV简单用法（二）"><div class="item__cover"><img src="undefined" alt="OpenCV简单用法（二）"></div><div class="item__info"><h3 class="item__title">OpenCV简单用法（二）</h3><span class="item__text">2018-04-30</span></div></a></li><li class="latest-post-item"><a href="/2018/04/20/LSTM预测股票走势/" title="LSTM预测股票走势"><div class="item__cover"><img src="undefined" alt="LSTM预测股票走势"></div><div class="item__info"><h3 class="item__title">LSTM预测股票走势</h3><span class="item__text">2018-04-20</span></div></a></li><li class="latest-post-item"><a href="/2018/04/17/朴素贝叶斯分类器的Python实现/" title="朴素贝叶斯分类器的Python实现"><div class="item__cover"><img src="undefined" alt="朴素贝叶斯分类器的Python实现"></div><div class="item__info"><h3 class="item__title">朴素贝叶斯分类器的Python实现</h3><span class="item__text">2018-04-17</span></div></a></li></ul></div><div class="sidebar__block"><h3 class="block__title">文章标签</h3><ul class="block-list tag-list clearfix"><li class="tag-item"><a class="tag-link" href="/tags/LSTM/">LSTM</a></li><li class="tag-item"><a class="tag-link" href="/tags/OpenCV/">OpenCV</a></li><li class="tag-item"><a class="tag-link" href="/tags/Python/">Python</a></li><li class="tag-item"><a class="tag-link" href="/tags/TensorFlow/">TensorFlow</a></li><li class="tag-item"><a class="tag-link" href="/tags/回归/">回归</a></li><li class="tag-item"><a class="tag-link" href="/tags/图像处理/">图像处理</a></li><li class="tag-item"><a class="tag-link" href="/tags/时间序列/">时间序列</a></li><li class="tag-item"><a class="tag-link" href="/tags/机器学习/">机器学习</a></li><li class="tag-item"><a class="tag-link" href="/tags/深度学习/">深度学习</a></li><li class="tag-item"><a class="tag-link" href="/tags/线性回归/">线性回归</a></li><li class="tag-item"><a class="tag-link" href="/tags/贝叶斯/">贝叶斯</a></li></ul></div></aside></main><footer class="page__footer"><section class="footer__top"><div class="page__container footer__container"><div class="footer-top__item footer-top__item--2"><h3 class="item__title">关于</h3><div class="item__content"><p class="item__text"></p><ul class="footer__contact-info"><li class="contact-info__item"><i class="iconfont icon-address"></i> <span></span></li><li class="contact-info__item"><i class="iconfont icon-email2"></i> <span></span></li></ul></div></div></div></section><section class="footer__bottom"><div class="page__container footer__container"><p class="footer__copyright">© <a href="https://github.com/Mrminfive/hexo-theme-skapp" target="_blank">Skapp</a> 2017 powered by <a href="http://hexo.io/" target="_blank">Hexo</a>, made by <a href="https://github.com/Mrminfive" target="_blank">minfive</a>.</p><ul class="footer__social-network clearfix"></ul></div></section></footer><div id="back-top" class="back-top back-top--hidden js-hidden"><i class="iconfont icon-top"></i></div></div><script src="/js/common.js"></script><script src="/js/page/post.js"></script><script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true,
                skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
            });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
                for (i=0; i < all.length; i += 1) {
                all[i].SourceElement().parentNode.className += ' has-jax';
                }
            });</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>